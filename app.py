import streamlit as st
import os
from dotenv import load_dotenv

# --- 1. æ ¸å¿ƒç»„ä»¶å¯¼å…¥ ---
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# --- 2. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å…¨èƒ½AIå­¦ä¹ åŠ©æ‰‹", page_icon="ğŸ“")
st.title("ğŸ“ å…¨èƒ½ AI å­¦ä¹ åŠ©æ‰‹")

# --- 3. çŠ¶æ€ç®¡ç† (Session State) ---
if "chat_store" not in st.session_state:
    st.session_state["chat_store"] = ChatMessageHistory()
    # åˆå§‹æ¬¢è¿è¯­
    st.session_state["chat_store"].add_ai_message("ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„å…¨èƒ½å­¦ä¹ åŠ©æ‰‹ã€‚è¯·é€‰æ‹©å­¦ç§‘å¼€å§‹æé—®å§ï¼")

# è¾…åŠ©å‡½æ•°ï¼šè·å–å†å²è®°å½•
def get_session_history(session_id: str):
    return st.session_state["chat_store"]

# --- 4. ä¾§è¾¹æ è®¾ç½® (åŠŸèƒ½å‡çº§åŒº) ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # 4.1 å­¦ç§‘æ‰©å±•ï¼šæ–°å¢ ç”Ÿç‰©ã€ç‰©ç†
    subject = st.selectbox(
        "ğŸ“š é€‰æ‹©å­¦ç§‘", 
        options=["è®¡ç®—æœº", "æ•°å­¦", "ç‰©ç†", "ç”Ÿç‰©", "æ–‡å­¦", "å†å²"]
    )
    
    # 4.2 é£æ ¼é€‰æ‹©
    style = st.selectbox(
        "ğŸ—£ï¸ è®²è§£é£æ ¼", 
        options=["ç®€æ´ç›´æ¥", "è¯¦ç»†æ•™å­¦", "è‹æ ¼æ‹‰åº•å¼å¼•å¯¼"]
    )
    
    # 4.3 é«˜çº§è®¾ç½®ï¼šåˆ›é€ åŠ›å‚æ•° (æ–°å¢åŠŸèƒ½)
    with st.expander("ğŸ› ï¸ æ¨¡å‹å‚æ•° (é«˜çº§)"):
        temperature = st.slider(
            "åˆ›é€ åŠ› (Temperature)", 
            min_value=0.0, max_value=1.0, value=0.3, step=0.1,
            help="æ•°å€¼è¶Šé«˜å›ç­”è¶Šéšæœºå‘æ•£ï¼Œæ•°å€¼è¶Šä½è¶Šä¸¥è°¨ã€‚ç†ç§‘å»ºè®®è°ƒä½ï¼Œæ–‡ç§‘å»ºè®®è°ƒé«˜ã€‚"
        )
    
    # 4.4 æ¸…ç©ºå¯¹è¯æŒ‰é’® (æ–°å¢åŠŸèƒ½)
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰å¯¹è¯", use_container_width=True):
        st.session_state["chat_store"].clear()
        st.session_state["chat_store"].add_ai_message(f"å·²é‡ç½®ã€‚ç°åœ¨æˆ‘ä»¬å¼€å§‹èŠèŠå…³äº **{subject}** çš„è¯é¢˜å§ï¼")
        st.rerun()

# --- 5. èŠå¤©ç•Œé¢æ¸²æŸ“ ---
# éå†å†å²è®°å½•å¹¶æ˜¾ç¤º
for msg in st.session_state["chat_store"].messages:
    role = "assistant" if msg.type == "ai" else "human"
    # é’ˆå¯¹ä»£ç å’Œå…¬å¼ä¼˜åŒ–æ˜¾ç¤º
    st.chat_message(role).write(msg.content)

# --- 6. æ ¸å¿ƒé€»è¾‘ (LCELé“¾) ---
def get_chain(subject, style, temperature):
    # 6.1 æ¨¡å‹åˆå§‹åŒ– (åŠ¨æ€ä¼ å…¥ temperature)
    llm = ChatOpenAI(
        api_key=os.getenv("OPENAI_API_KEY"),
        model="deepseek-chat", # æˆ– gpt-3.5-turbo
        base_url="https://api.deepseek.com",
        temperature=temperature,
        streaming=True # å¼€å¯æµå¼æ”¯æŒ
    )

    # 6.2 é£æ ¼ä¸æç¤ºè¯å­—å…¸
    style_prompts = {
        "ç®€æ´ç›´æ¥": "ç›´æ¥ç»™å‡ºæ ¸å¿ƒç­”æ¡ˆï¼Œä¸è¦åºŸè¯ã€‚å¦‚æœæ˜¯ç†ç§‘é—®é¢˜ï¼Œç›´æ¥åˆ—å‡ºå…¬å¼å’Œç»“æœã€‚",
        "è¯¦ç»†æ•™å­¦": "åƒè€å¸ˆä¸€æ ·å¾ªå¾ªå–„è¯±ã€‚1. å…ˆç»™å‡ºç›´æ¥ç»“è®ºï¼›2. é€æ­¥æ‹†è§£åŸç†ï¼›3. ä¸¾ä¸€ä¸ªç”Ÿæ´»ä¸­çš„ä¾‹å­æ¥ç±»æ¯”ã€‚",
        "è‹æ ¼æ‹‰åº•å¼å¼•å¯¼": "ä¸è¦ç›´æ¥ç»™ç­”æ¡ˆã€‚é€šè¿‡åé—®å’Œæç¤ºï¼Œå¼•å¯¼ç”¨æˆ·è‡ªå·±æ€è€ƒå‡ºç­”æ¡ˆã€‚ä¸€æ­¥æ­¥å¼•å¯¼ã€‚"
    }

    # 6.3 ç³»ç»Ÿæç¤ºè¯ (é’ˆå¯¹ç‰©ç†/ç”Ÿç‰©åšäº†ä¼˜åŒ–)
    # ç‰¹åˆ«å¢åŠ äº† LaTeX æ ¼å¼è¯´æ˜ï¼Œè¿™å¯¹ç‰©ç†/æ•°å­¦å¾ˆé‡è¦
    system_prompt = f"""ä½ æ˜¯ {{subject}} é¢†åŸŸçš„èµ„æ·±ä¸“å®¶å¯¼å¸ˆã€‚
    
    è¯·éµå¾ªä»¥ä¸‹è®²è§£é£æ ¼ï¼š
    {style_prompts[style]}
    
    æ³¨æ„äº‹é¡¹ï¼š
    1. å¦‚æœæ¶‰åŠå…¬å¼ï¼Œè¯·ä½¿ç”¨ LaTeX æ ¼å¼ï¼ˆä¾‹å¦‚ $E=mc^2$ï¼‰ã€‚
    2. å¦‚æœæ¶‰åŠç”Ÿç‰©/åŒ–å­¦ååº”ï¼Œè¯·æ¸…æ™°åˆ—å‡ºååº”å¼ã€‚
    3. å¦‚æœæ¶‰åŠä»£ç ï¼Œè¯·ä½¿ç”¨ä»£ç å—ã€‚
    4. ä¸¥å‰æ‹’ç»å›ç­”ä¸ {{subject}} æ— å…³çš„å¨±ä¹å…«å¦é—®é¢˜ã€‚
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}"),
    ])

    # 6.4 ç»„è£…é“¾
    chain = prompt | llm | StrOutputParser()
    
    # 6.5 æŒ‚è½½è®°å¿†
    chain_with_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    
    return chain_with_history

# --- 7. å¤„ç†ç”¨æˆ·è¾“å…¥ ---
user_input = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜...")

if user_input:
    # 7.1 æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    st.chat_message("human").write(user_input)
    
    # 7.2 è·å–å¤„ç†é“¾
    chain = get_chain(subject, style, temperature)
    
    # 7.3 æµå¼è¾“å‡º (Streaming) - ç”¨æˆ·ä½“éªŒæ ¸å¿ƒå‡çº§
    with st.chat_message("assistant"):
        # ä½¿ç”¨ st.write_stream é…åˆ chain.stream å®ç°æ‰“å­—æœºæ•ˆæœ
        # config ä¸­ä¼ å…¥ session_id ä»¥åŒ¹é…å†å²è®°å½•
        response = st.write_stream(
            chain.stream(
                {"input": user_input, "subject": subject},
                config={"configurable": {"session_id": "current_session"}}
            )
        )
    
    # æ³¨æ„ï¼šä½¿ç”¨ st.write_stream åï¼ŒStreamlit ä¸ä¼šè‡ªåŠ¨æŠŠ AI çš„å®Œæ•´å›å¤å­˜å…¥ memory å¯¹è±¡å—ï¼Ÿ
    # ç­”æ¡ˆæ˜¯ï¼šRunnableWithMessageHistory ä¼šåœ¨ stream ç»“æŸæ—¶è‡ªåŠ¨ä¿å­˜ã€‚
    # ä½†ä¸ºäº†ä¿é™©èµ·è§å’Œç«‹å³æ›´æ–°çŠ¶æ€ï¼Œæœ‰æ—¶éœ€è¦æ‰‹åŠ¨åˆ·æ–°æˆ–ä¾èµ–ä¸‹ä¸€æ¬¡ rerunã€‚
    # åœ¨è¿™é‡Œï¼ŒLangChain çš„ RunnableWithMessageHistory ä¼šè‡ªåŠ¨å¤„ç†å¥½åç«¯å­˜å‚¨ã€‚